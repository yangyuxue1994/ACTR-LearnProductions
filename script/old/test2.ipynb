{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6254d5d-2d44-43a3-a288-ec122711015b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e52b4da-fa91-4055-b8bf-7f10807c71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLeaning:\n",
    "\n",
    "    def __init__(self,alpha = 0.1,gamma = 0.6,epsilon = 0.1,epochs=5000):\n",
    "        self.alpha=alpha\n",
    "        self.gamma=gamma\n",
    "        self.epsilon=epsilon\n",
    "        self.epochs=epochs\n",
    "\n",
    "    def state_to_number(self, state):\n",
    "        state = state.reshape(9)\n",
    "        number = 0\n",
    "        for i, num in enumerate(state):\n",
    "            number += num * 3 ** (len(state) - i - 1)\n",
    "        return int(number)\n",
    "\n",
    "    def number_to_state(self,number):\n",
    "        state = np.zeros(9)\n",
    "        nums = []\n",
    "        while number:\n",
    "            number, r = divmod(number, 3)\n",
    "            nums.append(r)\n",
    "        state[len(state) - len(nums):] = np.array(nums)[::-1]\n",
    "        return state.reshape((3, 3))\n",
    "\n",
    "    def q_table(self,env):\n",
    "        q_table=np.zeros((3**9, env.action_space.n))\n",
    "        return q_table\n",
    "\n",
    "    def learn(self,env):\n",
    "        if env.env_name==\"tictactoe\":\n",
    "            self.q_table = self.q_table(env)\n",
    "            for i in range(self.epochs):\n",
    "                state = env.reset()\n",
    "\n",
    "                epochs, penalties, reward, = 0, 0, 0\n",
    "                done = False\n",
    "\n",
    "                while done !=True:\n",
    "                    if random.uniform(0, 1) < self.epsilon:\n",
    "                        action = env.action_space.sample()  # Explore action space\n",
    "                        #forbiden ilegal action\n",
    "                        while state[int(action / 3)][action % 3] !=0:\n",
    "                            action=env.action_space.sample()\n",
    "                    else:\n",
    "                        action_value_list=self.q_table[self.state_to_number(state)]\n",
    "                        for action,action_value in enumerate(action_value_list):\n",
    "                            if state[int(action / 3)][action % 3]!=0:\n",
    "                                action_value_list[action]=np.nan\n",
    "                        action = np.nanargmax(action_value_list)  # Exploit learned values\n",
    "                    next_state, reward, done, info = env.step(action)\n",
    "                    old_value = self.q_table[self.state_to_number(state), action]\n",
    "                    next_max = np.nanmax(self.q_table[self.state_to_number(next_state)])\n",
    "                    new_value = (1 - self.alpha) * old_value + self.alpha * (reward + self.gamma * next_max)\n",
    "                    self.q_table[self.state_to_number(state), action] = new_value\n",
    "                    state = next_state\n",
    "\n",
    "                    epochs += 1\n",
    "        return self.q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34fdf754-56b1-4e23-97f3-a1c46a660922",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "q_table() missing 1 required positional argument: 'env'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-decb6b601092>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mQLeaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: q_table() missing 1 required positional argument: 'env'"
     ]
    }
   ],
   "source": [
    "QLeaning().q_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "359c6562-b984-46f4-a2bd-fc41ec7eaf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = TicTacToe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa2effc-5b2e-4f13-87a7-36cfe638949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09a6bc06-da02-42cf-8acf-cf4269fb37b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0. 0. 0.] [0. 0. 0.]\n",
      "1 [0. 0. 0.] [0. 0. 0.]\n",
      "2 [0. 0. 0.] [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "t.states.reshape(9)\n",
    "number = 0\n",
    "for i, num in enumerate(t.states):\n",
    "    number += num * 3 ** (len(t.states) - i - 1)\n",
    "    print(i, num, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e2f172d-6fc6-4628-b3f3-51a89fbdc865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7156758-9a9f-4217-8444-3f9ad2eb8af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box(0.0, 2.0, (3, 3), float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84afc59c-05ba-462c-95fc-82ad3715771e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
